{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b412fa62-66d6-4650-b0fb-e587a4a41dd9",
   "metadata": {},
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32256be0-af27-49d9-accc-fd47a1139870",
   "metadata": {},
   "source": [
    "A1. Web scraping is an automated technique to extract data from websites. It's used to efficiently gather and organize data from the internet for various purposes. This includes collecting information for market research, competitive analysis, academic research, and real-time data monitoring.\n",
    "\n",
    "Why Web Scraping is Used:\n",
    "Data Collection and Analysis:\n",
    "Gathering large amounts of data from the web for analysis, market trends, consumer sentiment, and more.\n",
    "\n",
    "Competitive Intelligence:\n",
    "Monitoring and analyzing competitor websites for product details, pricing, and strategies.\n",
    "\n",
    "Research and Academic Studies:\n",
    "Extracting data for academic purposes, such as research papers, studies, or data analysis in various fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5018f05c-0dab-4d47-b6e5-359731815cb7",
   "metadata": {},
   "source": [
    "Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d715f1-8085-4075-87b3-423076f9db33",
   "metadata": {},
   "source": [
    "A2.The different methods used for Web Scraping are :\n",
    "\n",
    "HTTP Requests and APIs:\n",
    "Utilizing HTTP requests and APIs to retrieve data from websites.\n",
    "\n",
    "HTML Parsing:\n",
    "Parsing HTML content to extract specific data using parsing libraries like Beautiful Soup.\n",
    "\n",
    "XPath and CSS Selectors:\n",
    "Using XPath and CSS selectors to navigate and extract data from HTML structure.\n",
    "\n",
    "Regular Expressions:\n",
    "Applying regular expressions to match and extract patterns in the web page's content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f04b7f4-026d-440a-baf1-9210670a79ae",
   "metadata": {},
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a124cb-5de7-43e9-a75b-d4a4e2ed9cda",
   "metadata": {},
   "source": [
    "A3. Beautiful Soup is a Python library used for web scraping. It parses HTML and XML documents, creating a parse tree for traversing, searching, and manipulating the parsed content easily. It simplifies the process of extracting specific data elements from web pages by providing Pythonic ways to navigate and search the parsed content, making web scraping more efficient and convenient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abba966-c087-48a3-a0ea-ce33b49ae1fa",
   "metadata": {},
   "source": [
    "Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813bacdf-1456-43b3-bc06-eda3c94be1ba",
   "metadata": {},
   "source": [
    "A4. Flask is used in web scraping projects to create web applications, enabling easy integration of web scraping logic, handling HTTP requests and responses, presenting scraped data, and offering API endpoints for data sharing. It simplifies web application development and enhances the user experience when interacting with the scraped data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145478cb-ba2b-4690-a9d6-595b2bb26ec1",
   "metadata": {},
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e288743-faa4-40e2-b5a0-bcc8306a5718",
   "metadata": {},
   "source": [
    "A5. I'll describe some AWS services commonly used in a web scraping project:\n",
    "\n",
    "1.Amazon EC2 (Elastic Compute Cloud):\n",
    "   - Use: Provides scalable compute capacity in the cloud.\n",
    "   - Explanation: EC2 instances can be used to host web scraping scripts, run the Flask application, or manage the backend of the project.\n",
    "\n",
    "2.Amazon S3 (Simple Storage Service):\n",
    "   - Use: Offers scalable object storage for storing and retrieving data.\n",
    "   - Explanation: S3 can be used to store the scraped data, any backup files, or static assets (like images) that the web scraping project uses.\n",
    "\n",
    "3.AWS Lambda:\n",
    "   - Use: Serverless computing service for running code in response to events.\n",
    "   - Explanation: Lambda functions can be triggered by events (e.g., new data in S3) and can perform specific tasks like data processing, analysis, or notifications.\n",
    "\n",
    "4.Amazon RDS (Relational Database Service):\n",
    "   - Use: Managed relational database service for various database engines (e.g., MySQL, PostgreSQL).\n",
    "   - Explanation: RDS can be used to store structured data from the web scraping, providing a reliable and scalable database solution.\n",
    "\n",
    "5.AWS Glue:\n",
    "   - Use: ETL (Extract, Transform, Load) service to prepare and transform data for analytics.\n",
    "   - Explanation: Glue can be used to process and transform the scraped data into a more structured and usable format before storing it in a database.\n",
    "\n",
    "6.Amazon API Gateway:\n",
    "   - Use: Fully managed service to create, publish, maintain, monitor, and secure APIs at scale.\n",
    "   - Explanation: API Gateway can be used to expose APIs for the scraped data, enabling access for other applications or services.\n",
    "\n",
    "These AWS services collectively support the web scraping project by providing scalable computing resources, storage solutions, data processing capabilities, databases, and API management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2c34c1-8795-476f-bb87-a4d6233ee059",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
